{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook, I tried transfer learning using Efficientnet as my base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Kaggle: Recursion Cellular Image Classification\n",
    "# https://www.kaggle.com/leighplt/densenet121-pytorch\n",
    "# https://stackoverflow.com/questions/43264816/need-help-combining-two-3-channel-images-into-6-channel-image-python\n",
    "# https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/\n",
    "# https://github.com/keras-team/keras/issues/4664\n",
    "# https://www.machinecurve.com/index.php/2019/10/18/a-simple-conv3d-example-with-keras/\n",
    "\n",
    "# Efficientnet\n",
    "# https://www.dlology.com/blog/transfer-learning-with-efficientnet/\n",
    "# https://github.com/titu1994/keras-efficientnets\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(251)\n",
    "os.environ['PYTHONHASHSEED']=str(251)\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalMaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "from keras_efficientnets import EfficientNetB0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1155\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "project_path = r'D:\\UCBerkeley\\CourseWork\\202001\\W251\\Homework\\Project'\n",
    "dir_openpose = 'openpose_output'\n",
    "dir_train = 'NEW4_image_transfer_trial3'\n",
    "dir_test = 'NEW4_manual_optical_flow_output_trial3'\n",
    "model_name = 'ResNet50_model_weights_NEW4_trial3_model2.h5'\n",
    "\n",
    "TRAIN_DIR = os.path.join(project_path, dir_openpose, dir_train)\n",
    "# class_list = ['AGAIN', 'ALL', 'AWKWARD', 'BASEBALL', 'BEHAVIOR', 'CAN', 'CHAT', 'CHEAP', \n",
    "#               'CHEAT', 'CHURCH', 'COAT', 'CONFLICT', 'COURT', 'DEPOSIT', 'DEPRESS', \n",
    "#               'DOCTOR', 'DRESS', 'ENOUGH', 'NEG']\n",
    "y_train_lst = [f.split('_')[1] for f in os.listdir(os.path.join(project_path, dir_openpose, dir_test)) if 'train' in f]\n",
    "class_list = np.unique(y_train_lst)\n",
    "sample_class_weights = class_weight.compute_class_weight('balanced', class_list, y_train_lst)\n",
    "\n",
    "HEIGHT = 300\n",
    "WIDTH = 300\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "num_train_images = len([f for f in os.listdir(os.path.join(project_path, dir_openpose, dir_test)) \n",
    "                        if 'train' in f])\n",
    "print(num_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Found 1155 images belonging to 19 classes.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\Angela\\Anaconda3\\envs\\w251_project3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(Tensor(\"in..., outputs=Tensor(\"sw...)`\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Reference: https://keras.io/preprocessing/image/\n",
    "# Reference: https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "train_datagen =  ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    # Below are the parameters used for crop\n",
    "    # zoom_range=[0.8, 1.2], \n",
    "    # width_shift_range=[-50,50]\n",
    "    # Below are the parameters used for no crop\n",
    "    zoom_range=[0.7, 1.3], \n",
    "    # width shift means up and down\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range = 0.2\n",
    "    )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n",
    "                                                    target_size=(HEIGHT, WIDTH), \n",
    "                                                    batch_size=BATCH_SIZE)\n",
    "base_model = EfficientNetB0(input_shape=(HEIGHT, WIDTH, 3), include_top=False, weights='imagenet')\n",
    "# base_model = ResNet50(weights='imagenet', \n",
    "#                       include_top=False, \n",
    "#                       input_shape=(HEIGHT, WIDTH, 3))\n",
    "base_output = base_model.layers[-1].output\n",
    "# base_output = base_model.layers[5].output\n",
    "# base_output = Flatten()(base_output)\n",
    "base_model = Model(base_model.input, output=base_output)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# base_model.trainable = True\n",
    "# set_trainable = False\n",
    "# for layer in base_model.layers:\n",
    "#     if layer.name in ['res5c_branch2c']:\n",
    "#         set_trainable = True\n",
    "#     if set_trainable:\n",
    "#         layer.trainable = True\n",
    "#     else:\n",
    "#         layer.trainable = False\n",
    "        \n",
    "# layers = [(layer, layer.name, layer.trainable) for layer in base_model.layers]\n",
    "# pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']).tail(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            (None, 300, 300, 3)  0                                            \n__________________________________________________________________________________________________\nconv2d_66 (Conv2D)              (None, 150, 150, 32) 864         input_2[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_50 (BatchNo (None, 150, 150, 32) 128         conv2d_66[0][0]                  \n__________________________________________________________________________________________________\nswish_50 (Swish)                (None, 150, 150, 32) 0           batch_normalization_50[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_17 (DepthwiseC (None, 150, 150, 32) 288         swish_50[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_51 (BatchNo (None, 150, 150, 32) 128         depthwise_conv2d_17[0][0]        \n__________________________________________________________________________________________________\nswish_51 (Swish)                (None, 150, 150, 32) 0           batch_normalization_51[0][0]     \n__________________________________________________________________________________________________\nlambda_17 (Lambda)              (None, 1, 1, 32)     0           swish_51[0][0]                   \n__________________________________________________________________________________________________\nconv2d_67 (Conv2D)              (None, 1, 1, 8)      264         lambda_17[0][0]                  \n__________________________________________________________________________________________________\nswish_52 (Swish)                (None, 1, 1, 8)      0           conv2d_67[0][0]                  \n__________________________________________________________________________________________________\nconv2d_68 (Conv2D)              (None, 1, 1, 32)     288         swish_52[0][0]                   \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 1, 1, 32)     0           conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nmultiply_17 (Multiply)          (None, 150, 150, 32) 0           activation_17[0][0]              \n                                                                 swish_51[0][0]                   \n__________________________________________________________________________________________________\nconv2d_69 (Conv2D)              (None, 150, 150, 16) 512         multiply_17[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_52 (BatchNo (None, 150, 150, 16) 64          conv2d_69[0][0]                  \n__________________________________________________________________________________________________\nconv2d_70 (Conv2D)              (None, 150, 150, 96) 1536        batch_normalization_52[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_53 (BatchNo (None, 150, 150, 96) 384         conv2d_70[0][0]                  \n__________________________________________________________________________________________________\nswish_53 (Swish)                (None, 150, 150, 96) 0           batch_normalization_53[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_18 (DepthwiseC (None, 75, 75, 96)   864         swish_53[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_54 (BatchNo (None, 75, 75, 96)   384         depthwise_conv2d_18[0][0]        \n__________________________________________________________________________________________________\nswish_54 (Swish)                (None, 75, 75, 96)   0           batch_normalization_54[0][0]     \n__________________________________________________________________________________________________\nlambda_18 (Lambda)              (None, 1, 1, 96)     0           swish_54[0][0]                   \n__________________________________________________________________________________________________\nconv2d_71 (Conv2D)              (None, 1, 1, 4)      388         lambda_18[0][0]                  \n__________________________________________________________________________________________________\nswish_55 (Swish)                (None, 1, 1, 4)      0           conv2d_71[0][0]                  \n__________________________________________________________________________________________________\nconv2d_72 (Conv2D)              (None, 1, 1, 96)     480         swish_55[0][0]                   \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 1, 1, 96)     0           conv2d_72[0][0]                  \n__________________________________________________________________________________________________\nmultiply_18 (Multiply)          (None, 75, 75, 96)   0           activation_18[0][0]              \n                                                                 swish_54[0][0]                   \n__________________________________________________________________________________________________\nconv2d_73 (Conv2D)              (None, 75, 75, 24)   2304        multiply_18[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_55 (BatchNo (None, 75, 75, 24)   96          conv2d_73[0][0]                  \n__________________________________________________________________________________________________\nconv2d_74 (Conv2D)              (None, 75, 75, 144)  3456        batch_normalization_55[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_56 (BatchNo (None, 75, 75, 144)  576         conv2d_74[0][0]                  \n__________________________________________________________________________________________________\nswish_56 (Swish)                (None, 75, 75, 144)  0           batch_normalization_56[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_19 (DepthwiseC (None, 75, 75, 144)  1296        swish_56[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_57 (BatchNo (None, 75, 75, 144)  576         depthwise_conv2d_19[0][0]        \n__________________________________________________________________________________________________\nswish_57 (Swish)                (None, 75, 75, 144)  0           batch_normalization_57[0][0]     \n__________________________________________________________________________________________________\nlambda_19 (Lambda)              (None, 1, 1, 144)    0           swish_57[0][0]                   \n__________________________________________________________________________________________________\nconv2d_75 (Conv2D)              (None, 1, 1, 6)      870         lambda_19[0][0]                  \n__________________________________________________________________________________________________\nswish_58 (Swish)                (None, 1, 1, 6)      0           conv2d_75[0][0]                  \n__________________________________________________________________________________________________\nconv2d_76 (Conv2D)              (None, 1, 1, 144)    1008        swish_58[0][0]                   \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 1, 1, 144)    0           conv2d_76[0][0]                  \n__________________________________________________________________________________________________\nmultiply_19 (Multiply)          (None, 75, 75, 144)  0           activation_19[0][0]              \n                                                                 swish_57[0][0]                   \n__________________________________________________________________________________________________\nconv2d_77 (Conv2D)              (None, 75, 75, 24)   3456        multiply_19[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_58 (BatchNo (None, 75, 75, 24)   96          conv2d_77[0][0]                  \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 75, 75, 24)   0           batch_normalization_58[0][0]     \n                                                                 batch_normalization_55[0][0]     \n__________________________________________________________________________________________________\nconv2d_78 (Conv2D)              (None, 75, 75, 144)  3456        add_10[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_59 (BatchNo (None, 75, 75, 144)  576         conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nswish_59 (Swish)                (None, 75, 75, 144)  0           batch_normalization_59[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_20 (DepthwiseC (None, 38, 38, 144)  3600        swish_59[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_60 (BatchNo (None, 38, 38, 144)  576         depthwise_conv2d_20[0][0]        \n__________________________________________________________________________________________________\nswish_60 (Swish)                (None, 38, 38, 144)  0           batch_normalization_60[0][0]     \n__________________________________________________________________________________________________\nlambda_20 (Lambda)              (None, 1, 1, 144)    0           swish_60[0][0]                   \n__________________________________________________________________________________________________\nconv2d_79 (Conv2D)              (None, 1, 1, 6)      870         lambda_20[0][0]                  \n__________________________________________________________________________________________________\nswish_61 (Swish)                (None, 1, 1, 6)      0           conv2d_79[0][0]                  \n__________________________________________________________________________________________________\nconv2d_80 (Conv2D)              (None, 1, 1, 144)    1008        swish_61[0][0]                   \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 1, 1, 144)    0           conv2d_80[0][0]                  \n__________________________________________________________________________________________________\nmultiply_20 (Multiply)          (None, 38, 38, 144)  0           activation_20[0][0]              \n                                                                 swish_60[0][0]                   \n__________________________________________________________________________________________________\nconv2d_81 (Conv2D)              (None, 38, 38, 40)   5760        multiply_20[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_61 (BatchNo (None, 38, 38, 40)   160         conv2d_81[0][0]                  \n__________________________________________________________________________________________________\nconv2d_82 (Conv2D)              (None, 38, 38, 240)  9600        batch_normalization_61[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_62 (BatchNo (None, 38, 38, 240)  960         conv2d_82[0][0]                  \n__________________________________________________________________________________________________\nswish_62 (Swish)                (None, 38, 38, 240)  0           batch_normalization_62[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_21 (DepthwiseC (None, 38, 38, 240)  6000        swish_62[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_63 (BatchNo (None, 38, 38, 240)  960         depthwise_conv2d_21[0][0]        \n__________________________________________________________________________________________________\nswish_63 (Swish)                (None, 38, 38, 240)  0           batch_normalization_63[0][0]     \n__________________________________________________________________________________________________\nlambda_21 (Lambda)              (None, 1, 1, 240)    0           swish_63[0][0]                   \n__________________________________________________________________________________________________\nconv2d_83 (Conv2D)              (None, 1, 1, 10)     2410        lambda_21[0][0]                  \n__________________________________________________________________________________________________\nswish_64 (Swish)                (None, 1, 1, 10)     0           conv2d_83[0][0]                  \n__________________________________________________________________________________________________\nconv2d_84 (Conv2D)              (None, 1, 1, 240)    2640        swish_64[0][0]                   \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 1, 1, 240)    0           conv2d_84[0][0]                  \n__________________________________________________________________________________________________\nmultiply_21 (Multiply)          (None, 38, 38, 240)  0           activation_21[0][0]              \n                                                                 swish_63[0][0]                   \n__________________________________________________________________________________________________\nconv2d_85 (Conv2D)              (None, 38, 38, 40)   9600        multiply_21[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_64 (BatchNo (None, 38, 38, 40)   160         conv2d_85[0][0]                  \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 38, 38, 40)   0           batch_normalization_64[0][0]     \n                                                                 batch_normalization_61[0][0]     \n__________________________________________________________________________________________________\nconv2d_86 (Conv2D)              (None, 38, 38, 240)  9600        add_11[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_65 (BatchNo (None, 38, 38, 240)  960         conv2d_86[0][0]                  \n__________________________________________________________________________________________________\nswish_65 (Swish)                (None, 38, 38, 240)  0           batch_normalization_65[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_22 (DepthwiseC (None, 19, 19, 240)  2160        swish_65[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_66 (BatchNo (None, 19, 19, 240)  960         depthwise_conv2d_22[0][0]        \n__________________________________________________________________________________________________\nswish_66 (Swish)                (None, 19, 19, 240)  0           batch_normalization_66[0][0]     \n__________________________________________________________________________________________________\nlambda_22 (Lambda)              (None, 1, 1, 240)    0           swish_66[0][0]                   \n__________________________________________________________________________________________________\nconv2d_87 (Conv2D)              (None, 1, 1, 10)     2410        lambda_22[0][0]                  \n__________________________________________________________________________________________________\nswish_67 (Swish)                (None, 1, 1, 10)     0           conv2d_87[0][0]                  \n__________________________________________________________________________________________________\nconv2d_88 (Conv2D)              (None, 1, 1, 240)    2640        swish_67[0][0]                   \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 1, 1, 240)    0           conv2d_88[0][0]                  \n__________________________________________________________________________________________________\nmultiply_22 (Multiply)          (None, 19, 19, 240)  0           activation_22[0][0]              \n                                                                 swish_66[0][0]                   \n__________________________________________________________________________________________________\nconv2d_89 (Conv2D)              (None, 19, 19, 80)   19200       multiply_22[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_67 (BatchNo (None, 19, 19, 80)   320         conv2d_89[0][0]                  \n__________________________________________________________________________________________________\nconv2d_90 (Conv2D)              (None, 19, 19, 480)  38400       batch_normalization_67[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_68 (BatchNo (None, 19, 19, 480)  1920        conv2d_90[0][0]                  \n__________________________________________________________________________________________________\nswish_68 (Swish)                (None, 19, 19, 480)  0           batch_normalization_68[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_23 (DepthwiseC (None, 19, 19, 480)  4320        swish_68[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_69 (BatchNo (None, 19, 19, 480)  1920        depthwise_conv2d_23[0][0]        \n__________________________________________________________________________________________________\nswish_69 (Swish)                (None, 19, 19, 480)  0           batch_normalization_69[0][0]     \n__________________________________________________________________________________________________\nlambda_23 (Lambda)              (None, 1, 1, 480)    0           swish_69[0][0]                   \n__________________________________________________________________________________________________\nconv2d_91 (Conv2D)              (None, 1, 1, 20)     9620        lambda_23[0][0]                  \n__________________________________________________________________________________________________\nswish_70 (Swish)                (None, 1, 1, 20)     0           conv2d_91[0][0]                  \n__________________________________________________________________________________________________\nconv2d_92 (Conv2D)              (None, 1, 1, 480)    10080       swish_70[0][0]                   \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 1, 1, 480)    0           conv2d_92[0][0]                  \n__________________________________________________________________________________________________\nmultiply_23 (Multiply)          (None, 19, 19, 480)  0           activation_23[0][0]              \n                                                                 swish_69[0][0]                   \n__________________________________________________________________________________________________\nconv2d_93 (Conv2D)              (None, 19, 19, 80)   38400       multiply_23[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_70 (BatchNo (None, 19, 19, 80)   320         conv2d_93[0][0]                  \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 19, 19, 80)   0           batch_normalization_70[0][0]     \n                                                                 batch_normalization_67[0][0]     \n__________________________________________________________________________________________________\nconv2d_94 (Conv2D)              (None, 19, 19, 480)  38400       add_12[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_71 (BatchNo (None, 19, 19, 480)  1920        conv2d_94[0][0]                  \n__________________________________________________________________________________________________\nswish_71 (Swish)                (None, 19, 19, 480)  0           batch_normalization_71[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_24 (DepthwiseC (None, 19, 19, 480)  4320        swish_71[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_72 (BatchNo (None, 19, 19, 480)  1920        depthwise_conv2d_24[0][0]        \n__________________________________________________________________________________________________\nswish_72 (Swish)                (None, 19, 19, 480)  0           batch_normalization_72[0][0]     \n__________________________________________________________________________________________________\nlambda_24 (Lambda)              (None, 1, 1, 480)    0           swish_72[0][0]                   \n__________________________________________________________________________________________________\nconv2d_95 (Conv2D)              (None, 1, 1, 20)     9620        lambda_24[0][0]                  \n__________________________________________________________________________________________________\nswish_73 (Swish)                (None, 1, 1, 20)     0           conv2d_95[0][0]                  \n__________________________________________________________________________________________________\nconv2d_96 (Conv2D)              (None, 1, 1, 480)    10080       swish_73[0][0]                   \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 1, 1, 480)    0           conv2d_96[0][0]                  \n__________________________________________________________________________________________________\nmultiply_24 (Multiply)          (None, 19, 19, 480)  0           activation_24[0][0]              \n                                                                 swish_72[0][0]                   \n__________________________________________________________________________________________________\nconv2d_97 (Conv2D)              (None, 19, 19, 80)   38400       multiply_24[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_73 (BatchNo (None, 19, 19, 80)   320         conv2d_97[0][0]                  \n__________________________________________________________________________________________________\nadd_13 (Add)                    (None, 19, 19, 80)   0           batch_normalization_73[0][0]     \n                                                                 add_12[0][0]                     \n__________________________________________________________________________________________________\nconv2d_98 (Conv2D)              (None, 19, 19, 480)  38400       add_13[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_74 (BatchNo (None, 19, 19, 480)  1920        conv2d_98[0][0]                  \n__________________________________________________________________________________________________\nswish_74 (Swish)                (None, 19, 19, 480)  0           batch_normalization_74[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_25 (DepthwiseC (None, 19, 19, 480)  12000       swish_74[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_75 (BatchNo (None, 19, 19, 480)  1920        depthwise_conv2d_25[0][0]        \n__________________________________________________________________________________________________\nswish_75 (Swish)                (None, 19, 19, 480)  0           batch_normalization_75[0][0]     \n__________________________________________________________________________________________________\nlambda_25 (Lambda)              (None, 1, 1, 480)    0           swish_75[0][0]                   \n__________________________________________________________________________________________________\nconv2d_99 (Conv2D)              (None, 1, 1, 20)     9620        lambda_25[0][0]                  \n__________________________________________________________________________________________________\nswish_76 (Swish)                (None, 1, 1, 20)     0           conv2d_99[0][0]                  \n__________________________________________________________________________________________________\nconv2d_100 (Conv2D)             (None, 1, 1, 480)    10080       swish_76[0][0]                   \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 1, 1, 480)    0           conv2d_100[0][0]                 \n__________________________________________________________________________________________________\nmultiply_25 (Multiply)          (None, 19, 19, 480)  0           activation_25[0][0]              \n                                                                 swish_75[0][0]                   \n__________________________________________________________________________________________________\nconv2d_101 (Conv2D)             (None, 19, 19, 112)  53760       multiply_25[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_76 (BatchNo (None, 19, 19, 112)  448         conv2d_101[0][0]                 \n__________________________________________________________________________________________________\nconv2d_102 (Conv2D)             (None, 19, 19, 672)  75264       batch_normalization_76[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_77 (BatchNo (None, 19, 19, 672)  2688        conv2d_102[0][0]                 \n__________________________________________________________________________________________________\nswish_77 (Swish)                (None, 19, 19, 672)  0           batch_normalization_77[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_26 (DepthwiseC (None, 19, 19, 672)  16800       swish_77[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_78 (BatchNo (None, 19, 19, 672)  2688        depthwise_conv2d_26[0][0]        \n__________________________________________________________________________________________________\nswish_78 (Swish)                (None, 19, 19, 672)  0           batch_normalization_78[0][0]     \n__________________________________________________________________________________________________\nlambda_26 (Lambda)              (None, 1, 1, 672)    0           swish_78[0][0]                   \n__________________________________________________________________________________________________\nconv2d_103 (Conv2D)             (None, 1, 1, 28)     18844       lambda_26[0][0]                  \n__________________________________________________________________________________________________\nswish_79 (Swish)                (None, 1, 1, 28)     0           conv2d_103[0][0]                 \n__________________________________________________________________________________________________\nconv2d_104 (Conv2D)             (None, 1, 1, 672)    19488       swish_79[0][0]                   \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 1, 1, 672)    0           conv2d_104[0][0]                 \n__________________________________________________________________________________________________\nmultiply_26 (Multiply)          (None, 19, 19, 672)  0           activation_26[0][0]              \n                                                                 swish_78[0][0]                   \n__________________________________________________________________________________________________\nconv2d_105 (Conv2D)             (None, 19, 19, 112)  75264       multiply_26[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_79 (BatchNo (None, 19, 19, 112)  448         conv2d_105[0][0]                 \n__________________________________________________________________________________________________\nadd_14 (Add)                    (None, 19, 19, 112)  0           batch_normalization_79[0][0]     \n                                                                 batch_normalization_76[0][0]     \n__________________________________________________________________________________________________\nconv2d_106 (Conv2D)             (None, 19, 19, 672)  75264       add_14[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_80 (BatchNo (None, 19, 19, 672)  2688        conv2d_106[0][0]                 \n__________________________________________________________________________________________________\nswish_80 (Swish)                (None, 19, 19, 672)  0           batch_normalization_80[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_27 (DepthwiseC (None, 19, 19, 672)  16800       swish_80[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_81 (BatchNo (None, 19, 19, 672)  2688        depthwise_conv2d_27[0][0]        \n__________________________________________________________________________________________________\nswish_81 (Swish)                (None, 19, 19, 672)  0           batch_normalization_81[0][0]     \n__________________________________________________________________________________________________\nlambda_27 (Lambda)              (None, 1, 1, 672)    0           swish_81[0][0]                   \n__________________________________________________________________________________________________\nconv2d_107 (Conv2D)             (None, 1, 1, 28)     18844       lambda_27[0][0]                  \n__________________________________________________________________________________________________\nswish_82 (Swish)                (None, 1, 1, 28)     0           conv2d_107[0][0]                 \n__________________________________________________________________________________________________\nconv2d_108 (Conv2D)             (None, 1, 1, 672)    19488       swish_82[0][0]                   \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 1, 1, 672)    0           conv2d_108[0][0]                 \n__________________________________________________________________________________________________\nmultiply_27 (Multiply)          (None, 19, 19, 672)  0           activation_27[0][0]              \n                                                                 swish_81[0][0]                   \n__________________________________________________________________________________________________\nconv2d_109 (Conv2D)             (None, 19, 19, 112)  75264       multiply_27[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_82 (BatchNo (None, 19, 19, 112)  448         conv2d_109[0][0]                 \n__________________________________________________________________________________________________\nadd_15 (Add)                    (None, 19, 19, 112)  0           batch_normalization_82[0][0]     \n                                                                 add_14[0][0]                     \n__________________________________________________________________________________________________\nconv2d_110 (Conv2D)             (None, 19, 19, 672)  75264       add_15[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_83 (BatchNo (None, 19, 19, 672)  2688        conv2d_110[0][0]                 \n__________________________________________________________________________________________________\nswish_83 (Swish)                (None, 19, 19, 672)  0           batch_normalization_83[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_28 (DepthwiseC (None, 10, 10, 672)  16800       swish_83[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_84 (BatchNo (None, 10, 10, 672)  2688        depthwise_conv2d_28[0][0]        \n__________________________________________________________________________________________________\nswish_84 (Swish)                (None, 10, 10, 672)  0           batch_normalization_84[0][0]     \n__________________________________________________________________________________________________\nlambda_28 (Lambda)              (None, 1, 1, 672)    0           swish_84[0][0]                   \n__________________________________________________________________________________________________\nconv2d_111 (Conv2D)             (None, 1, 1, 28)     18844       lambda_28[0][0]                  \n__________________________________________________________________________________________________\nswish_85 (Swish)                (None, 1, 1, 28)     0           conv2d_111[0][0]                 \n__________________________________________________________________________________________________\nconv2d_112 (Conv2D)             (None, 1, 1, 672)    19488       swish_85[0][0]                   \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 1, 1, 672)    0           conv2d_112[0][0]                 \n__________________________________________________________________________________________________\nmultiply_28 (Multiply)          (None, 10, 10, 672)  0           activation_28[0][0]              \n                                                                 swish_84[0][0]                   \n__________________________________________________________________________________________________\nconv2d_113 (Conv2D)             (None, 10, 10, 192)  129024      multiply_28[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_85 (BatchNo (None, 10, 10, 192)  768         conv2d_113[0][0]                 \n__________________________________________________________________________________________________\nconv2d_114 (Conv2D)             (None, 10, 10, 1152) 221184      batch_normalization_85[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_86 (BatchNo (None, 10, 10, 1152) 4608        conv2d_114[0][0]                 \n__________________________________________________________________________________________________\nswish_86 (Swish)                (None, 10, 10, 1152) 0           batch_normalization_86[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_29 (DepthwiseC (None, 10, 10, 1152) 28800       swish_86[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_87 (BatchNo (None, 10, 10, 1152) 4608        depthwise_conv2d_29[0][0]        \n__________________________________________________________________________________________________\nswish_87 (Swish)                (None, 10, 10, 1152) 0           batch_normalization_87[0][0]     \n__________________________________________________________________________________________________\nlambda_29 (Lambda)              (None, 1, 1, 1152)   0           swish_87[0][0]                   \n__________________________________________________________________________________________________\nconv2d_115 (Conv2D)             (None, 1, 1, 48)     55344       lambda_29[0][0]                  \n__________________________________________________________________________________________________\nswish_88 (Swish)                (None, 1, 1, 48)     0           conv2d_115[0][0]                 \n__________________________________________________________________________________________________\nconv2d_116 (Conv2D)             (None, 1, 1, 1152)   56448       swish_88[0][0]                   \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 1, 1, 1152)   0           conv2d_116[0][0]                 \n__________________________________________________________________________________________________\nmultiply_29 (Multiply)          (None, 10, 10, 1152) 0           activation_29[0][0]              \n                                                                 swish_87[0][0]                   \n__________________________________________________________________________________________________\nconv2d_117 (Conv2D)             (None, 10, 10, 192)  221184      multiply_29[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_88 (BatchNo (None, 10, 10, 192)  768         conv2d_117[0][0]                 \n__________________________________________________________________________________________________\nadd_16 (Add)                    (None, 10, 10, 192)  0           batch_normalization_88[0][0]     \n                                                                 batch_normalization_85[0][0]     \n__________________________________________________________________________________________________\nconv2d_118 (Conv2D)             (None, 10, 10, 1152) 221184      add_16[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_89 (BatchNo (None, 10, 10, 1152) 4608        conv2d_118[0][0]                 \n__________________________________________________________________________________________________\nswish_89 (Swish)                (None, 10, 10, 1152) 0           batch_normalization_89[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_30 (DepthwiseC (None, 10, 10, 1152) 28800       swish_89[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_90 (BatchNo (None, 10, 10, 1152) 4608        depthwise_conv2d_30[0][0]        \n__________________________________________________________________________________________________\nswish_90 (Swish)                (None, 10, 10, 1152) 0           batch_normalization_90[0][0]     \n__________________________________________________________________________________________________\nlambda_30 (Lambda)              (None, 1, 1, 1152)   0           swish_90[0][0]                   \n__________________________________________________________________________________________________\nconv2d_119 (Conv2D)             (None, 1, 1, 48)     55344       lambda_30[0][0]                  \n__________________________________________________________________________________________________\nswish_91 (Swish)                (None, 1, 1, 48)     0           conv2d_119[0][0]                 \n__________________________________________________________________________________________________\nconv2d_120 (Conv2D)             (None, 1, 1, 1152)   56448       swish_91[0][0]                   \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 1, 1, 1152)   0           conv2d_120[0][0]                 \n__________________________________________________________________________________________________\nmultiply_30 (Multiply)          (None, 10, 10, 1152) 0           activation_30[0][0]              \n                                                                 swish_90[0][0]                   \n__________________________________________________________________________________________________\nconv2d_121 (Conv2D)             (None, 10, 10, 192)  221184      multiply_30[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_91 (BatchNo (None, 10, 10, 192)  768         conv2d_121[0][0]                 \n__________________________________________________________________________________________________\nadd_17 (Add)                    (None, 10, 10, 192)  0           batch_normalization_91[0][0]     \n                                                                 add_16[0][0]                     \n__________________________________________________________________________________________________\nconv2d_122 (Conv2D)             (None, 10, 10, 1152) 221184      add_17[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_92 (BatchNo (None, 10, 10, 1152) 4608        conv2d_122[0][0]                 \n__________________________________________________________________________________________________\nswish_92 (Swish)                (None, 10, 10, 1152) 0           batch_normalization_92[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_31 (DepthwiseC (None, 10, 10, 1152) 28800       swish_92[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_93 (BatchNo (None, 10, 10, 1152) 4608        depthwise_conv2d_31[0][0]        \n__________________________________________________________________________________________________\nswish_93 (Swish)                (None, 10, 10, 1152) 0           batch_normalization_93[0][0]     \n__________________________________________________________________________________________________\nlambda_31 (Lambda)              (None, 1, 1, 1152)   0           swish_93[0][0]                   \n__________________________________________________________________________________________________\nconv2d_123 (Conv2D)             (None, 1, 1, 48)     55344       lambda_31[0][0]                  \n__________________________________________________________________________________________________\nswish_94 (Swish)                (None, 1, 1, 48)     0           conv2d_123[0][0]                 \n__________________________________________________________________________________________________\nconv2d_124 (Conv2D)             (None, 1, 1, 1152)   56448       swish_94[0][0]                   \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 1, 1, 1152)   0           conv2d_124[0][0]                 \n__________________________________________________________________________________________________\nmultiply_31 (Multiply)          (None, 10, 10, 1152) 0           activation_31[0][0]              \n                                                                 swish_93[0][0]                   \n__________________________________________________________________________________________________\nconv2d_125 (Conv2D)             (None, 10, 10, 192)  221184      multiply_31[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_94 (BatchNo (None, 10, 10, 192)  768         conv2d_125[0][0]                 \n__________________________________________________________________________________________________\nadd_18 (Add)                    (None, 10, 10, 192)  0           batch_normalization_94[0][0]     \n                                                                 add_17[0][0]                     \n__________________________________________________________________________________________________\nconv2d_126 (Conv2D)             (None, 10, 10, 1152) 221184      add_18[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_95 (BatchNo (None, 10, 10, 1152) 4608        conv2d_126[0][0]                 \n__________________________________________________________________________________________________\nswish_95 (Swish)                (None, 10, 10, 1152) 0           batch_normalization_95[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_32 (DepthwiseC (None, 10, 10, 1152) 10368       swish_95[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_96 (BatchNo (None, 10, 10, 1152) 4608        depthwise_conv2d_32[0][0]        \n__________________________________________________________________________________________________\nswish_96 (Swish)                (None, 10, 10, 1152) 0           batch_normalization_96[0][0]     \n__________________________________________________________________________________________________\nlambda_32 (Lambda)              (None, 1, 1, 1152)   0           swish_96[0][0]                   \n__________________________________________________________________________________________________\nconv2d_127 (Conv2D)             (None, 1, 1, 48)     55344       lambda_32[0][0]                  \n__________________________________________________________________________________________________\nswish_97 (Swish)                (None, 1, 1, 48)     0           conv2d_127[0][0]                 \n__________________________________________________________________________________________________\nconv2d_128 (Conv2D)             (None, 1, 1, 1152)   56448       swish_97[0][0]                   \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 1, 1, 1152)   0           conv2d_128[0][0]                 \n__________________________________________________________________________________________________\nmultiply_32 (Multiply)          (None, 10, 10, 1152) 0           activation_32[0][0]              \n                                                                 swish_96[0][0]                   \n__________________________________________________________________________________________________\nconv2d_129 (Conv2D)             (None, 10, 10, 320)  368640      multiply_32[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_97 (BatchNo (None, 10, 10, 320)  1280        conv2d_129[0][0]                 \n__________________________________________________________________________________________________\nconv2d_130 (Conv2D)             (None, 10, 10, 1280) 409600      batch_normalization_97[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_98 (BatchNo (None, 10, 10, 1280) 5120        conv2d_130[0][0]                 \n__________________________________________________________________________________________________\nswish_98 (Swish)                (None, 10, 10, 1280) 0           batch_normalization_98[0][0]     \n==================================================================================================\nTotal params: 4,049,564\nTrainable params: 0\nNon-trainable params: 4,049,564\n__________________________________________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "base_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test_config = base_model.get_layer('input_1').get_config()\n",
    "# test_config['batch_input_shape'] = (None, 300, 300, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmodel_4 (Model)              (None, 10, 10, 1280)      4049564   \n_________________________________________________________________\nflatten (Flatten)            (None, 128000)            0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128000)            0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 19)                2432019   \n=================================================================\nTotal params: 6,481,583\nTrainable params: 2,432,019\nNon-trainable params: 4,049,564\n_________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "# model.add(GlobalMaxPooling2D(name=\"gap\"))\n",
    "model.add(Flatten(name=\"flatten\"))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(class_list), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.00001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "\r 1/72 [..............................] - ETA: 3:31 - loss: 3.6413 - accuracy: 0.0625",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2/72 [..............................] - ETA: 3:05 - loss: 3.8521 - accuracy: 0.0312",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/72 [>.............................] - ETA: 2:54 - loss: 4.0797 - accuracy: 0.0208",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/72 [>.............................] - ETA: 2:45 - loss: 4.2973 - accuracy: 0.0469",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/72 [=>............................] - ETA: 2:36 - loss: 4.1308 - accuracy: 0.0500",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6/72 [=>............................] - ETA: 2:29 - loss: 4.0223 - accuracy: 0.0521",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/72 [=>............................] - ETA: 2:23 - loss: 3.9579 - accuracy: 0.0536",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8/72 [==>...........................] - ETA: 2:18 - loss: 3.9770 - accuracy: 0.0547",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/72 [==>...........................] - ETA: 2:15 - loss: 3.9341 - accuracy: 0.0486",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/72 [===>..........................] - ETA: 2:11 - loss: 3.8902 - accuracy: 0.0500",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/72 [===>..........................] - ETA: 2:07 - loss: 3.8387 - accuracy: 0.0511",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/72 [====>.........................] - ETA: 2:04 - loss: 3.8815 - accuracy: 0.0469",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/72 [====>.........................] - ETA: 2:01 - loss: 3.9346 - accuracy: 0.0529",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/72 [====>.........................] - ETA: 1:58 - loss: 3.9136 - accuracy: 0.0536",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/72 [=====>........................] - ETA: 1:55 - loss: 3.9069 - accuracy: 0.0583",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/72 [=====>........................] - ETA: 1:53 - loss: 3.8838 - accuracy: 0.0547",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/72 [======>.......................] - ETA: 1:50 - loss: 3.8560 - accuracy: 0.0588",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18/72 [======>.......................] - ETA: 1:48 - loss: 3.8119 - accuracy: 0.0590",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/72 [======>.......................] - ETA: 1:46 - loss: 3.7766 - accuracy: 0.0625",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/72 [=======>......................] - ETA: 1:44 - loss: 3.7561 - accuracy: 0.0656",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/72 [=======>......................] - ETA: 1:41 - loss: 3.7348 - accuracy: 0.0685",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/72 [========>.....................] - ETA: 1:39 - loss: 3.7695 - accuracy: 0.0710",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/72 [========>.....................] - ETA: 1:37 - loss: 3.8547 - accuracy: 0.0707",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/72 [=========>....................] - ETA: 1:34 - loss: 3.8542 - accuracy: 0.0677",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/72 [=========>....................] - ETA: 1:32 - loss: 3.8656 - accuracy: 0.0650",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26/72 [=========>....................] - ETA: 1:30 - loss: 3.8534 - accuracy: 0.0649",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/72 [==========>...................] - ETA: 1:28 - loss: 3.8408 - accuracy: 0.0671",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/72 [==========>...................] - ETA: 1:26 - loss: 3.8639 - accuracy: 0.0647",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/72 [===========>..................] - ETA: 1:23 - loss: 3.8463 - accuracy: 0.0690",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30/72 [===========>..................] - ETA: 1:21 - loss: 3.8228 - accuracy: 0.0708",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/72 [===========>..................] - ETA: 1:19 - loss: 3.8018 - accuracy: 0.0706",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/72 [============>.................] - ETA: 1:17 - loss: 3.8062 - accuracy: 0.0723",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/72 [============>.................] - ETA: 1:15 - loss: 3.7976 - accuracy: 0.0720",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34/72 [=============>................] - ETA: 1:13 - loss: 3.7727 - accuracy: 0.0754",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/72 [=============>................] - ETA: 1:11 - loss: 3.7994 - accuracy: 0.0750",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r36/72 [==============>...............] - ETA: 1:09 - loss: 3.7717 - accuracy: 0.0764",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/72 [==============>...............] - ETA: 1:07 - loss: 3.7986 - accuracy: 0.0743",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r38/72 [==============>...............] - ETA: 1:05 - loss: 3.8060 - accuracy: 0.0740",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/72 [===============>..............] - ETA: 1:03 - loss: 3.7843 - accuracy: 0.0785",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/72 [===============>..............] - ETA: 1:01 - loss: 3.7565 - accuracy: 0.0812",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/72 [================>.............] - ETA: 59s - loss: 3.7598 - accuracy: 0.0823 ",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r42/72 [================>.............] - ETA: 57s - loss: 3.7568 - accuracy: 0.0833",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/72 [================>.............] - ETA: 55s - loss: 3.7437 - accuracy: 0.0828",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44/72 [=================>............] - ETA: 53s - loss: 3.7221 - accuracy: 0.0838",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/72 [=================>............] - ETA: 51s - loss: 3.7167 - accuracy: 0.0847",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r46/72 [==================>...........] - ETA: 49s - loss: 3.6961 - accuracy: 0.0856",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/72 [==================>...........] - ETA: 47s - loss: 3.6687 - accuracy: 0.0891",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r48/72 [===================>..........] - ETA: 45s - loss: 3.6591 - accuracy: 0.0872",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/72 [===================>..........] - ETA: 43s - loss: 3.6700 - accuracy: 0.0867",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/72 [===================>..........] - ETA: 41s - loss: 3.6559 - accuracy: 0.0862",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/72 [====================>.........] - ETA: 39s - loss: 3.6463 - accuracy: 0.0907",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r52/72 [====================>.........] - ETA: 37s - loss: 3.6232 - accuracy: 0.0913",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/72 [=====================>........] - ETA: 36s - loss: 3.6075 - accuracy: 0.0920",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/72 [=====================>........] - ETA: 34s - loss: 3.5955 - accuracy: 0.0914",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/72 [=====================>........] - ETA: 32s - loss: 3.5871 - accuracy: 0.0932",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/72 [======================>.......] - ETA: 30s - loss: 3.5709 - accuracy: 0.0926",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/72 [======================>.......] - ETA: 28s - loss: 3.5642 - accuracy: 0.0921",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r58/72 [=======================>......] - ETA: 26s - loss: 3.5535 - accuracy: 0.0916",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r59/72 [=======================>......] - ETA: 24s - loss: 3.5409 - accuracy: 0.0922",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/72 [========================>.....] - ETA: 22s - loss: 3.5327 - accuracy: 0.0938",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r61/72 [========================>.....] - ETA: 20s - loss: 3.5144 - accuracy: 0.0953",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r62/72 [========================>.....] - ETA: 18s - loss: 3.4987 - accuracy: 0.0968",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r63/72 [=========================>....] - ETA: 16s - loss: 3.4994 - accuracy: 0.0982",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r64/72 [=========================>....] - ETA: 15s - loss: 3.4959 - accuracy: 0.0977",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r65/72 [==========================>...] - ETA: 13s - loss: 3.4861 - accuracy: 0.0971",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r66/72 [==========================>...] - ETA: 11s - loss: 3.4771 - accuracy: 0.0975",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r67/72 [==========================>...] - ETA: 9s - loss: 3.4792 - accuracy: 0.0970 ",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r68/72 [===========================>..] - ETA: 7s - loss: 3.4661 - accuracy: 0.0983",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r69/72 [===========================>..] - ETA: 5s - loss: 3.4565 - accuracy: 0.1014",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r70/72 [============================>.] - ETA: 3s - loss: 3.4359 - accuracy: 0.1054",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r71/72 [============================>.] - ETA: 1s - loss: 3.4224 - accuracy: 0.1065",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r72/72 [==============================] - 134s 2s/step - loss: 3.4091 - accuracy: 0.1071\n",
      "Epoch 2/10\n",
      "\r 1/72 [..............................] - ETA: 2:16 - loss: 3.0419 - accuracy: 0.1250",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2/72 [..............................] - ETA: 2:12 - loss: 2.5557 - accuracy: 0.2500",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/72 [>.............................] - ETA: 2:10 - loss: 2.6537 - accuracy: 0.2083",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/72 [>.............................] - ETA: 2:09 - loss: 2.6168 - accuracy: 0.2344",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/72 [=>............................] - ETA: 2:06 - loss: 2.6180 - accuracy: 0.2125",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6/72 [=>............................] - ETA: 2:04 - loss: 2.7203 - accuracy: 0.1875",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/72 [=>............................] - ETA: 2:02 - loss: 2.7209 - accuracy: 0.1786",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8/72 [==>...........................] - ETA: 2:01 - loss: 2.7336 - accuracy: 0.1641",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/72 [==>...........................] - ETA: 1:59 - loss: 2.7125 - accuracy: 0.1736",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/72 [===>..........................] - ETA: 1:57 - loss: 2.7331 - accuracy: 0.1750",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/72 [===>..........................] - ETA: 1:55 - loss: 2.7708 - accuracy: 0.1705",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/72 [====>.........................] - ETA: 1:53 - loss: 2.8431 - accuracy: 0.1615",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/72 [====>.........................] - ETA: 1:51 - loss: 2.8188 - accuracy: 0.1538",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/72 [====>.........................] - ETA: 1:49 - loss: 2.7944 - accuracy: 0.1562",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/72 [=====>........................] - ETA: 1:47 - loss: 2.8602 - accuracy: 0.1583",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/72 [=====>........................] - ETA: 1:45 - loss: 2.8005 - accuracy: 0.1680",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/72 [======>.......................] - ETA: 1:43 - loss: 2.7829 - accuracy: 0.1691",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18/72 [======>.......................] - ETA: 1:41 - loss: 2.7726 - accuracy: 0.1597",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/72 [======>.......................] - ETA: 1:39 - loss: 2.7512 - accuracy: 0.1645",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/72 [=======>......................] - ETA: 1:37 - loss: 2.7303 - accuracy: 0.1656",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/72 [=======>......................] - ETA: 1:35 - loss: 2.7544 - accuracy: 0.1637",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/72 [========>.....................] - ETA: 1:33 - loss: 2.7479 - accuracy: 0.1591",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/72 [========>.....................] - ETA: 1:31 - loss: 2.7652 - accuracy: 0.1549",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/72 [=========>....................] - ETA: 1:29 - loss: 2.7663 - accuracy: 0.1562",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/72 [=========>....................] - ETA: 1:27 - loss: 2.7822 - accuracy: 0.1575",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26/72 [=========>....................] - ETA: 1:25 - loss: 2.7571 - accuracy: 0.1659",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/72 [==========>...................] - ETA: 1:24 - loss: 2.7596 - accuracy: 0.1667",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/72 [==========>...................] - ETA: 1:22 - loss: 2.7706 - accuracy: 0.1674",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/72 [===========>..................] - ETA: 1:20 - loss: 2.7418 - accuracy: 0.1767",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30/72 [===========>..................] - ETA: 1:18 - loss: 2.7264 - accuracy: 0.1792",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/72 [===========>..................] - ETA: 1:16 - loss: 2.7218 - accuracy: 0.1774",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/72 [============>.................] - ETA: 1:14 - loss: 2.7160 - accuracy: 0.1797",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/72 [============>.................] - ETA: 1:12 - loss: 2.6995 - accuracy: 0.1837",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34/72 [=============>................] - ETA: 1:10 - loss: 2.7081 - accuracy: 0.1801",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/72 [=============>................] - ETA: 1:09 - loss: 2.6977 - accuracy: 0.1875",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r36/72 [==============>...............] - ETA: 1:07 - loss: 2.7009 - accuracy: 0.1910",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/72 [==============>...............] - ETA: 1:05 - loss: 2.7070 - accuracy: 0.1875",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r38/72 [==============>...............] - ETA: 1:03 - loss: 2.6965 - accuracy: 0.1941",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/72 [===============>..............] - ETA: 1:01 - loss: 2.6695 - accuracy: 0.2035",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/72 [===============>..............] - ETA: 59s - loss: 2.7237 - accuracy: 0.2047 ",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/72 [================>.............] - ETA: 57s - loss: 2.7322 - accuracy: 0.2104",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r42/72 [================>.............] - ETA: 55s - loss: 2.7269 - accuracy: 0.2113",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/72 [================>.............] - ETA: 53s - loss: 2.7326 - accuracy: 0.2122",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44/72 [=================>............] - ETA: 52s - loss: 2.7313 - accuracy: 0.2131",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/72 [=================>............] - ETA: 50s - loss: 2.7497 - accuracy: 0.2139",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r46/72 [==================>...........] - ETA: 48s - loss: 2.7406 - accuracy: 0.2147",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/72 [==================>...........] - ETA: 46s - loss: 2.7440 - accuracy: 0.2141",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r48/72 [===================>..........] - ETA: 44s - loss: 2.7306 - accuracy: 0.2148",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/72 [===================>..........] - ETA: 42s - loss: 2.7252 - accuracy: 0.2168",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/72 [===================>..........] - ETA: 40s - loss: 2.7372 - accuracy: 0.2173",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/72 [====================>.........] - ETA: 38s - loss: 2.7304 - accuracy: 0.2192",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r52/72 [====================>.........] - ETA: 36s - loss: 2.7227 - accuracy: 0.2186",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/72 [=====================>........] - ETA: 34s - loss: 2.7157 - accuracy: 0.2192",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/72 [=====================>........] - ETA: 32s - loss: 2.7103 - accuracy: 0.2197",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/72 [=====================>........] - ETA: 31s - loss: 2.6911 - accuracy: 0.2215",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/72 [======================>.......] - ETA: 29s - loss: 2.6870 - accuracy: 0.2220",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/72 [======================>.......] - ETA: 27s - loss: 2.6899 - accuracy: 0.2225",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r58/72 [=======================>......] - ETA: 25s - loss: 2.6787 - accuracy: 0.2262",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r59/72 [=======================>......] - ETA: 23s - loss: 2.6705 - accuracy: 0.2256",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/72 [========================>.....] - ETA: 21s - loss: 2.6663 - accuracy: 0.2281",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r61/72 [========================>.....] - ETA: 20s - loss: 2.6604 - accuracy: 0.2295",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r62/72 [========================>.....] - ETA: 18s - loss: 2.6650 - accuracy: 0.2278",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r63/72 [=========================>....] - ETA: 16s - loss: 2.6521 - accuracy: 0.2302",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r64/72 [=========================>....] - ETA: 14s - loss: 2.6512 - accuracy: 0.2315",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r65/72 [==========================>...] - ETA: 12s - loss: 2.6423 - accuracy: 0.2317",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r66/72 [==========================>...] - ETA: 10s - loss: 2.6355 - accuracy: 0.2359",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r67/72 [==========================>...] - ETA: 9s - loss: 2.6367 - accuracy: 0.2389 ",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r68/72 [===========================>..] - ETA: 7s - loss: 2.6299 - accuracy: 0.2409",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r69/72 [===========================>..] - ETA: 5s - loss: 2.6322 - accuracy: 0.2411",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r70/72 [============================>.] - ETA: 3s - loss: 2.6202 - accuracy: 0.2430",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r71/72 [============================>.] - ETA: 1s - loss: 2.6106 - accuracy: 0.2458",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r72/72 [==============================] - 132s 2s/step - loss: 2.6087 - accuracy: 0.2458\n",
      "Epoch 3/10\n",
      "\r 1/72 [..............................] - ETA: 2:12 - loss: 4.1037 - accuracy: 0.1250",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2/72 [..............................] - ETA: 2:11 - loss: 3.5031 - accuracy: 0.1875",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/72 [>.............................] - ETA: 2:09 - loss: 3.0869 - accuracy: 0.1875",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/72 [>.............................] - ETA: 2:08 - loss: 3.0500 - accuracy: 0.2031",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/72 [=>............................] - ETA: 2:06 - loss: 2.9507 - accuracy: 0.2000",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6/72 [=>............................] - ETA: 2:04 - loss: 2.7982 - accuracy: 0.2083",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/72 [=>............................] - ETA: 2:02 - loss: 2.6750 - accuracy: 0.2321",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8/72 [==>...........................] - ETA: 2:00 - loss: 2.6464 - accuracy: 0.2266",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/72 [==>...........................] - ETA: 1:58 - loss: 2.7097 - accuracy: 0.2222",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/72 [===>..........................] - ETA: 1:56 - loss: 2.7525 - accuracy: 0.2188",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/72 [===>..........................] - ETA: 1:54 - loss: 2.6892 - accuracy: 0.2273",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/72 [====>.........................] - ETA: 1:52 - loss: 2.6248 - accuracy: 0.2396",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/72 [====>.........................] - ETA: 1:51 - loss: 2.6306 - accuracy: 0.2404",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/72 [====>.........................] - ETA: 1:49 - loss: 2.6194 - accuracy: 0.2411",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/72 [=====>........................] - ETA: 1:47 - loss: 2.5512 - accuracy: 0.2458",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/72 [=====>........................] - ETA: 1:45 - loss: 2.5252 - accuracy: 0.2422",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/72 [======>.......................] - ETA: 1:38 - loss: 2.4519 - accuracy: 0.2471",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18/72 [======>.......................] - ETA: 1:36 - loss: 2.4110 - accuracy: 0.2618",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/72 [======>.......................] - ETA: 1:35 - loss: 2.4007 - accuracy: 0.2749",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/72 [=======>......................] - ETA: 1:33 - loss: 2.3700 - accuracy: 0.2736",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/72 [=======>......................] - ETA: 1:31 - loss: 2.3858 - accuracy: 0.2724",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/72 [========>.....................] - ETA: 1:30 - loss: 2.4171 - accuracy: 0.2684",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/72 [========>.....................] - ETA: 1:28 - loss: 2.3955 - accuracy: 0.2789",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/72 [=========>....................] - ETA: 1:26 - loss: 2.4024 - accuracy: 0.2722",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/72 [=========>....................] - ETA: 1:24 - loss: 2.3756 - accuracy: 0.2739",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26/72 [=========>....................] - ETA: 1:23 - loss: 2.3685 - accuracy: 0.2804",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/72 [==========>...................] - ETA: 1:21 - loss: 2.3697 - accuracy: 0.2840",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/72 [==========>...................] - ETA: 1:19 - loss: 2.3787 - accuracy: 0.2851",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/72 [===========>..................] - ETA: 1:17 - loss: 2.3561 - accuracy: 0.2905",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30/72 [===========>..................] - ETA: 1:16 - loss: 2.3438 - accuracy: 0.2976",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/72 [===========>..................] - ETA: 1:14 - loss: 2.3550 - accuracy: 0.2940",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/72 [============>.................] - ETA: 1:12 - loss: 2.3411 - accuracy: 0.2986",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/72 [============>.................] - ETA: 1:10 - loss: 2.3378 - accuracy: 0.3029",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34/72 [=============>................] - ETA: 1:08 - loss: 2.3139 - accuracy: 0.3089",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/72 [=============>................] - ETA: 1:07 - loss: 2.3106 - accuracy: 0.3126",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r36/72 [==============>...............] - ETA: 1:05 - loss: 2.3077 - accuracy: 0.3144",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/72 [==============>...............] - ETA: 1:03 - loss: 2.2911 - accuracy: 0.3143",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r38/72 [==============>...............] - ETA: 1:01 - loss: 2.2763 - accuracy: 0.3193",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/72 [===============>..............] - ETA: 1:00 - loss: 2.2806 - accuracy: 0.3224",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/72 [===============>..............] - ETA: 58s - loss: 2.2831 - accuracy: 0.3206 ",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/72 [================>.............] - ETA: 56s - loss: 2.2863 - accuracy: 0.3235",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r42/72 [================>.............] - ETA: 54s - loss: 2.2838 - accuracy: 0.3232",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/72 [================>.............] - ETA: 53s - loss: 2.2779 - accuracy: 0.3304",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44/72 [=================>............] - ETA: 51s - loss: 2.2535 - accuracy: 0.3386",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/72 [=================>............] - ETA: 49s - loss: 2.2516 - accuracy: 0.3352",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r46/72 [==================>...........] - ETA: 47s - loss: 2.2462 - accuracy: 0.3347",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/72 [==================>...........] - ETA: 46s - loss: 2.2439 - accuracy: 0.3302",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r48/72 [===================>..........] - ETA: 44s - loss: 2.2372 - accuracy: 0.3325",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/72 [===================>..........] - ETA: 42s - loss: 2.2400 - accuracy: 0.3294",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/72 [===================>..........] - ETA: 40s - loss: 2.2272 - accuracy: 0.3316",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/72 [====================>.........] - ETA: 39s - loss: 2.2309 - accuracy: 0.3313",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r52/72 [====================>.........] - ETA: 37s - loss: 2.2278 - accuracy: 0.3333",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/72 [=====================>........] - ETA: 35s - loss: 2.2258 - accuracy: 0.3341",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/72 [=====================>........] - ETA: 33s - loss: 2.2272 - accuracy: 0.3302",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/72 [=====================>........] - ETA: 31s - loss: 2.2178 - accuracy: 0.3345",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/72 [======================>.......] - ETA: 29s - loss: 2.2154 - accuracy: 0.3352",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/72 [======================>.......] - ETA: 28s - loss: 2.2067 - accuracy: 0.3382",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r58/72 [=======================>......] - ETA: 26s - loss: 2.2071 - accuracy: 0.3377",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r59/72 [=======================>......] - ETA: 24s - loss: 2.2015 - accuracy: 0.3394",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/72 [========================>.....] - ETA: 22s - loss: 2.2057 - accuracy: 0.3411",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r61/72 [========================>.....] - ETA: 20s - loss: 2.2064 - accuracy: 0.3427",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r62/72 [========================>.....] - ETA: 18s - loss: 2.1947 - accuracy: 0.3483",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r63/72 [=========================>....] - ETA: 16s - loss: 2.1853 - accuracy: 0.3508",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r64/72 [=========================>....] - ETA: 15s - loss: 2.1940 - accuracy: 0.3492",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r65/72 [==========================>...] - ETA: 13s - loss: 2.1952 - accuracy: 0.3496",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r66/72 [==========================>...] - ETA: 11s - loss: 2.1917 - accuracy: 0.3480",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r67/72 [==========================>...] - ETA: 9s - loss: 2.1910 - accuracy: 0.3503 ",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r68/72 [===========================>..] - ETA: 7s - loss: 2.2144 - accuracy: 0.3498",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r69/72 [===========================>..] - ETA: 5s - loss: 2.2121 - accuracy: 0.3511",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r70/72 [============================>.] - ETA: 3s - loss: 2.2011 - accuracy: 0.3550",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r71/72 [============================>.] - ETA: 1s - loss: 2.1923 - accuracy: 0.3562",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r72/72 [==============================] - 137s 2s/step - loss: 2.1830 - accuracy: 0.3582\n",
      "Epoch 4/10\n",
      "\r 1/72 [..............................] - ETA: 2:19 - loss: 1.6896 - accuracy: 0.5625",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2/72 [..............................] - ETA: 2:15 - loss: 1.7509 - accuracy: 0.5000",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/72 [>.............................] - ETA: 2:15 - loss: 2.0196 - accuracy: 0.4167",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/72 [>.............................] - ETA: 2:14 - loss: 1.9539 - accuracy: 0.4219",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/72 [=>............................] - ETA: 2:12 - loss: 1.8523 - accuracy: 0.4625",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6/72 [=>............................] - ETA: 2:11 - loss: 1.9518 - accuracy: 0.4375",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/72 [=>............................] - ETA: 2:10 - loss: 2.0678 - accuracy: 0.4107",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8/72 [==>...........................] - ETA: 2:08 - loss: 2.0287 - accuracy: 0.4062",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/72 [==>...........................] - ETA: 2:06 - loss: 2.0117 - accuracy: 0.4097",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/72 [===>..........................] - ETA: 2:04 - loss: 1.9795 - accuracy: 0.4313",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/72 [===>..........................] - ETA: 2:02 - loss: 1.9504 - accuracy: 0.4375",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/72 [====>.........................] - ETA: 2:00 - loss: 1.9627 - accuracy: 0.4427",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/72 [====>.........................] - ETA: 1:57 - loss: 1.9753 - accuracy: 0.4375",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/72 [====>.........................] - ETA: 1:55 - loss: 1.9358 - accuracy: 0.4509",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/72 [=====>........................] - ETA: 1:53 - loss: 1.9223 - accuracy: 0.4417",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/72 [=====>........................] - ETA: 1:51 - loss: 1.9388 - accuracy: 0.4297",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/72 [======>.......................] - ETA: 1:49 - loss: 1.9347 - accuracy: 0.4301",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18/72 [======>.......................] - ETA: 1:47 - loss: 1.9250 - accuracy: 0.4167",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/72 [======>.......................] - ETA: 1:46 - loss: 1.9312 - accuracy: 0.4112",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/72 [=======>......................] - ETA: 1:44 - loss: 1.9508 - accuracy: 0.4062",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/72 [=======>......................] - ETA: 1:43 - loss: 1.9382 - accuracy: 0.4107",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/72 [========>.....................] - ETA: 1:41 - loss: 1.9396 - accuracy: 0.4119",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/72 [========>.....................] - ETA: 1:39 - loss: 1.9362 - accuracy: 0.4076",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/72 [=========>....................] - ETA: 1:37 - loss: 1.9047 - accuracy: 0.4193",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/72 [=========>....................] - ETA: 1:35 - loss: 1.9101 - accuracy: 0.4200"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, epochs=NUM_EPOCHS, \n",
    "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
    "                                       shuffle=True, class_weight=dict(enumerate(sample_class_weights)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss + accuracy\n",
    "def plot_training(history):\n",
    "    acc = history.history['accuracy']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.title('Training accuracy')\n",
    "    plt.show()\n",
    "\n",
    "plot_training(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "# model_saved = load_model(os.path.join(project_path, model_name))\n",
    "# model_saved = finetune_model\n",
    "model_saved = model\n",
    "def conv_index_to_vocab(ind):\n",
    "    temp_dict = dict(enumerate(class_list))\n",
    "    return temp_dict[ind]\n",
    "def conv_vocab_to_index(vocab):\n",
    "    temp_dict = dict(zip(class_list,range(len(class_list))))\n",
    "    return temp_dict[vocab]\n",
    "\n",
    "print(conv_index_to_vocab(0))\n",
    "print(conv_vocab_to_index('NEG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "count = 0\n",
    "test_files_lst = [f for f in os.listdir(os.path.join(project_path, dir_openpose, dir_test)) \n",
    "                  if 'test' in f and 'sim0' in f]\n",
    "# test_files_lst = [f for f in os.listdir(os.path.join(project_path, dir_openpose, dir_test)) \n",
    "#                   if 'test' in f]\n",
    "for file in test_files_lst:\n",
    "    img = image.load_img(os.path.join(project_path,dir_openpose, dir_test,file), target_size=(300, 300))\n",
    "    x = image.img_to_array(img)\n",
    "    # print(x.shape)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    # print(x.shape)\n",
    "    x = preprocess_input(x)\n",
    "    y_pred = model_saved.predict(x)\n",
    "    print('-----------------')\n",
    "    print('Actual: ', file.split('_')[1])\n",
    "    print('Prediction: ', conv_index_to_vocab(np.argmax(y_pred)))\n",
    "    # print(y_pred)\n",
    "    count += 1\n",
    "    if file.split('_')[1] == conv_index_to_vocab(np.argmax(y_pred)):\n",
    "        correct_count += 1 \n",
    "    if count > 20:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(correct_count)\n",
    "print(len(test_files_lst))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}